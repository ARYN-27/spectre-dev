{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECTRE PROTOTYPE\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 20:57:53.157037: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-26 20:57:53.322449: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-26 20:57:53.323620: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-26 20:57:54.193166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from confluent_kafka import Producer, Consumer, KafkaError\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 20:57:58.454177: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-26 20:57:58.454485: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = tf.saved_model.load(\"../spectre-ann/Model/DDOS_2/A/SavedModel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_data_preprocess(df):\n",
    "    \n",
    "    dimensions_num_for_PCA = 7\n",
    "    \n",
    "    def clean_dataset(df):\n",
    "        assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "        df.dropna(inplace=True)\n",
    "        indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "        return df[indices_to_keep]\n",
    "\n",
    "    def get_PCA_feature_names(num_of_pca_components):\n",
    "        feature_names = []\n",
    "        for i in range(num_of_pca_components):    \n",
    "            feature_names.append(f\"Principal component {i+1}\")\n",
    "        return feature_names\n",
    "\n",
    "    # Clean the dataset.\n",
    "    df = clean_dataset(df)\n",
    "\n",
    "    # Reset the index and remove the unneeded index column.\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Check if the 'label' column exists in the DataFrame.\n",
    "    if 'label' in df.columns:\n",
    "        # Save the label attribute before dropping it.\n",
    "        df_labels = df['label']\n",
    "        df_no_labels = df.drop('label', axis=1)\n",
    "    else:\n",
    "        # If the 'label' column does not exist, use the DataFrame as is.\n",
    "        df_no_labels = df\n",
    "        df_labels = None\n",
    "\n",
    "    # Scale the data.\n",
    "    df_scaled = StandardScaler().fit_transform(df_no_labels)\n",
    "\n",
    "    # Perform PCA.\n",
    "    pca = PCA(n_components=7)\n",
    "    principal_components = pca.fit_transform(df_no_labels)\n",
    "\n",
    "    # Create a DataFrame with principal components.\n",
    "    principal_component_headings = get_PCA_feature_names(7)\n",
    "    df_pc = pd.DataFrame(data=principal_components, columns=principal_component_headings)\n",
    "\n",
    "    if df_labels is not None:\n",
    "        # Concatenate principal components and labels.\n",
    "        df_final = pd.concat([df_pc, df_labels], axis=1)\n",
    "\n",
    "        # Apply LabelBinarizer to the labels.\n",
    "        lb = LabelBinarizer()\n",
    "        df_final['label'] = lb.fit_transform(df_final['label'])\n",
    "    else:\n",
    "        df_final = df_pc\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zookeeper is running on port 2181\n",
      "Kafka is running on port 9092\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "\n",
    "# Check if Zookeeper is running on port 2181\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "result = sock.connect_ex(('localhost', 2181))\n",
    "if result == 0:\n",
    "    print(\"Zookeeper is running on port 2181\")\n",
    "else:\n",
    "    print(\"Zookeeper is not running on port 2181\")\n",
    "\n",
    "# Check if Kafka is running on port 9092\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "result = sock.connect_ex(('localhost', 9092))\n",
    "if result == 0:\n",
    "    print(\"Kafka is running on port 9092\")\n",
    "else:\n",
    "    print(\"Kafka is not running on port 9092\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kafka_producer(file_path, topic_name):\n",
    "    # Read the csv file.\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Preprocess the data using the prod_data_preprocess function.\n",
    "    df_preprocessed = prod_data_preprocess(df)\n",
    "\n",
    "    # Convert the dataframe to a list of dictionaries.\n",
    "    data = df_preprocessed.to_dict('records')\n",
    "\n",
    "    # Define the Kafka producer configuration.\n",
    "    producer_config = {\n",
    "        'bootstrap.servers': 'localhost:9092',\n",
    "        'client.id': 'python-producer'\n",
    "    }\n",
    "\n",
    "    # Create the Kafka producer.\n",
    "    producer = Producer(producer_config)\n",
    "\n",
    "    # Send each dictionary to the Kafka topic.\n",
    "    for record in data:\n",
    "        producer.produce(topic_name, key='key', value=str(record))\n",
    "\n",
    "    # Wait for any outstanding messages to be delivered and delivery reports to be received.\n",
    "    producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kafka_consumer(topic_name, saved_model_path):\n",
    "    # Define the Kafka consumer configuration.\n",
    "    consumer_config = {\n",
    "        'bootstrap.servers': 'localhost:9092',\n",
    "        'group.id': 'python-consumer',\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "\n",
    "    # Create the Kafka consumer.\n",
    "    consumer = Consumer(consumer_config)\n",
    "\n",
    "    # Subscribe to the Kafka topic.\n",
    "    consumer.subscribe([topic_name])\n",
    "\n",
    "    # Define the SavedModel configuration and load the model.\n",
    "    saved_model_config = tf.saved_model.LoadOptions(\n",
    "        experimental_io_device='/job:localhost'\n",
    "    )\n",
    "    saved_model = tf.saved_model.load(saved_model_path, options=saved_model_config)\n",
    "\n",
    "    # Define a function to process each message from the Kafka topic.\n",
    "    def process_message(msg):\n",
    "        # Parse the message and get the features.\n",
    "        features = json.loads(msg.value())\n",
    "        features_array = np.array(list(features.values()))\n",
    "\n",
    "        # Make a prediction using the SavedModel.\n",
    "        prediction = saved_model(features_array[tf.newaxis, ...])\n",
    "\n",
    "        # Calculate the detection rate.\n",
    "        detection_rate = np.argmax(prediction, axis=1)\n",
    "\n",
    "        return detection_rate\n",
    "\n",
    "    # Poll for new messages in the Kafka topic.\n",
    "    while True:\n",
    "        msg = consumer.poll(1.0)\n",
    "\n",
    "        if msg is None:\n",
    "            # No message received in the last poll interval.\n",
    "            continue\n",
    "        if msg.error():\n",
    "            # Handle any errors that occurred while polling for messages.\n",
    "            print(f\"Error while consuming message: {msg.error()}\")\n",
    "        else:\n",
    "            # Process the message and print the detection rate.\n",
    "            detection_rate = process_message(msg)\n",
    "            print(f\"Detection rate: {detection_rate}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
