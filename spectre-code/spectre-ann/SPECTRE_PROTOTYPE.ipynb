{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECTRE TEST\n",
    "- Using H5 Model trained using ISCX-IDS-2012 Dataset\n",
    "- Testing using Malware_Capture_Facility_Project Dataset - CTU-Malware-Capture-Botnet-135-1 Stlrat DDoS (MD5: `c7838b75ba10b0341554d25fbcc3bbc0`)\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from scapy.all import *\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "import seaborn as sns # Graphing, built ontop of MatPlot for ease-of-use and nicer diagrams.\n",
    "import sklearn # For Machine Learning algorithms\n",
    "import scikitplot # Confusion matrix plotting\n",
    "from sklearn.decomposition import PCA # For PCA dimensionality reduction technique\n",
    "from sklearn.preprocessing import StandardScaler # For scaling to unit scale, before PCA application\n",
    "from sklearn.preprocessing import LabelBinarizer # For converting categorical data into numeric, for modeling stage\n",
    "from scikitplot.metrics import plot_confusion_matrix # For plotting confusion matrices\n",
    "from sklearn.metrics import accuracy_score # For getting the accuracy of a model's predictions\n",
    "from sklearn.metrics import classification_report # Various metrics for model performance\n",
    "from sklearn.model_selection import StratifiedKFold # For optimal train_test splitting, for model input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAFKA IMPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHODS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISCX-IDS-2012 - 14 JUN\n",
    "#mal_pcap = scapy.rdpcap('/mnt/Data/SPECTRE/Dataset/ISCX-2012/PCAP/testbed-14jun.pcap') \n",
    "#training_sample = np.load('/home/aryn/spectre-dev/dataset/ISCX-IDS-2012/PCAP-NPY/destinationPayload_TestbedMonJun14Flows.xml.npy', allow_pickle=True)\n",
    "\n",
    "# Malware_Capture_Facility_Project - CTU-Malware-Capture-Botnet-135-1 Stlrat DDoS\n",
    "# malicious_data = np.load('/home/aryn/spectre-dev/dataset/Malware_Capture_Facility_Project/PCAP-NPY/2015-09-10_winlinux.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_mal = malicious_data[:2]\n",
    "table_mal = rows_mal.tolist()\n",
    "print(tabulate(table_mal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  -\n",
      "[ 43  79  75 ... 103 101 100]  0\n",
      "[ 46  46  46 ... 110  46  46]  0\n",
      "-----------------------------  -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryn/miniconda3/envs/spectre/lib/python3.9/site-packages/tabulate/__init__.py:107: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  (len(row) >= 1 and row[0] == SEPARATING_LINE)\n"
     ]
    }
   ],
   "source": [
    "rows_train = training_sample[:2]\n",
    "table_train = rows_train.tolist()\n",
    "print(tabulate(table_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PCA_feature_names(num_of_pca_components):\n",
    "    feature_names = []\n",
    "    for i in range(num_of_pca_components):    \n",
    "        feature_names.append(f\"Principal component {i+1}\")\n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Reduced dimensions' variable for altering the number of PCA principal components. Can be altered for needs.\n",
    "# Only 7 principal components needed when using non-normalised PCA dataset.\n",
    "dimensions_num_for_PCA = 7\n",
    "\n",
    "# Max number of permutations to run. Can be altered for needs.\n",
    "number_of_permutations = 100\n",
    "\n",
    "# 10 folds is usually the heuristic to follow for larger datasets of around this size.\n",
    "num_of_splits_for_skf = 10\n",
    "\n",
    "# Seed value to pass into models so that repeated runs result in the same output\n",
    "seed_val = 1\n",
    "\n",
    "# Number of statistical distance measures to run (for the results, columns section)\n",
    "num_of_statistical_dist_measures = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_Data = pd.read_csv('../../dataset/CICIDS2017/MachineLearningCSV/MachineLearningCVE/Monday-WorkingHours.pcap_ISCX.csv')\n",
    "df = Normal_Data.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_588891/2188718236.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
      "/tmp/ipykernel_588891/2188718236.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
      "/tmp/ipykernel_588891/2671744760.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.any and Series.any will be keyword-only.\n",
      "  indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Principal component 1</th>\n",
       "      <th>Principal component 2</th>\n",
       "      <th>Principal component 3</th>\n",
       "      <th>Principal component 4</th>\n",
       "      <th>Principal component 5</th>\n",
       "      <th>Principal component 6</th>\n",
       "      <th>Principal component 7</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.983320e+07</td>\n",
       "      <td>9.251362e+05</td>\n",
       "      <td>1.046049e+06</td>\n",
       "      <td>-128074.061738</td>\n",
       "      <td>-869081.641179</td>\n",
       "      <td>-9328.258030</td>\n",
       "      <td>10210.389224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.994976e+07</td>\n",
       "      <td>1.872796e+06</td>\n",
       "      <td>1.000291e+07</td>\n",
       "      <td>-124409.821468</td>\n",
       "      <td>-846672.396250</td>\n",
       "      <td>-10321.565566</td>\n",
       "      <td>10014.928220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.994976e+07</td>\n",
       "      <td>1.872796e+06</td>\n",
       "      <td>1.000291e+07</td>\n",
       "      <td>-124409.821468</td>\n",
       "      <td>-846672.396250</td>\n",
       "      <td>-10321.565566</td>\n",
       "      <td>10014.928220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.994976e+07</td>\n",
       "      <td>1.872796e+06</td>\n",
       "      <td>1.000291e+07</td>\n",
       "      <td>-124409.821468</td>\n",
       "      <td>-846672.396250</td>\n",
       "      <td>-10321.565566</td>\n",
       "      <td>10014.928220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.984615e+07</td>\n",
       "      <td>1.030431e+06</td>\n",
       "      <td>2.041257e+06</td>\n",
       "      <td>-127666.256450</td>\n",
       "      <td>-866593.042249</td>\n",
       "      <td>-9438.611625</td>\n",
       "      <td>10188.446052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529476</th>\n",
       "      <td>-1.978012e+07</td>\n",
       "      <td>6.112687e+05</td>\n",
       "      <td>-1.939024e+06</td>\n",
       "      <td>-133315.868223</td>\n",
       "      <td>-855223.925380</td>\n",
       "      <td>-9350.481582</td>\n",
       "      <td>16850.957232</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529477</th>\n",
       "      <td>-1.974771e+07</td>\n",
       "      <td>6.161432e+05</td>\n",
       "      <td>-1.935949e+06</td>\n",
       "      <td>-128750.407703</td>\n",
       "      <td>-841842.148056</td>\n",
       "      <td>-9094.307239</td>\n",
       "      <td>10005.865241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529478</th>\n",
       "      <td>-1.980753e+07</td>\n",
       "      <td>7.185561e+05</td>\n",
       "      <td>-9.063745e+05</td>\n",
       "      <td>-128879.080536</td>\n",
       "      <td>-873765.673193</td>\n",
       "      <td>-9182.189422</td>\n",
       "      <td>10266.382651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529479</th>\n",
       "      <td>-1.981276e+07</td>\n",
       "      <td>7.612775e+05</td>\n",
       "      <td>-5.024661e+05</td>\n",
       "      <td>-128678.971810</td>\n",
       "      <td>-872603.283762</td>\n",
       "      <td>-9206.582296</td>\n",
       "      <td>10228.529420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529480</th>\n",
       "      <td>-1.979441e+07</td>\n",
       "      <td>6.093061e+05</td>\n",
       "      <td>-1.939148e+06</td>\n",
       "      <td>-129305.317753</td>\n",
       "      <td>-876646.910220</td>\n",
       "      <td>-8970.163319</td>\n",
       "      <td>10285.549386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529481 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Principal component 1  Principal component 2  Principal component 3  \\\n",
       "0               -1.983320e+07           9.251362e+05           1.046049e+06   \n",
       "1               -1.994976e+07           1.872796e+06           1.000291e+07   \n",
       "2               -1.994976e+07           1.872796e+06           1.000291e+07   \n",
       "3               -1.994976e+07           1.872796e+06           1.000291e+07   \n",
       "4               -1.984615e+07           1.030431e+06           2.041257e+06   \n",
       "...                       ...                    ...                    ...   \n",
       "529476          -1.978012e+07           6.112687e+05          -1.939024e+06   \n",
       "529477          -1.974771e+07           6.161432e+05          -1.935949e+06   \n",
       "529478          -1.980753e+07           7.185561e+05          -9.063745e+05   \n",
       "529479          -1.981276e+07           7.612775e+05          -5.024661e+05   \n",
       "529480          -1.979441e+07           6.093061e+05          -1.939148e+06   \n",
       "\n",
       "        Principal component 4  Principal component 5  Principal component 6  \\\n",
       "0              -128074.061738         -869081.641179           -9328.258030   \n",
       "1              -124409.821468         -846672.396250          -10321.565566   \n",
       "2              -124409.821468         -846672.396250          -10321.565566   \n",
       "3              -124409.821468         -846672.396250          -10321.565566   \n",
       "4              -127666.256450         -866593.042249           -9438.611625   \n",
       "...                       ...                    ...                    ...   \n",
       "529476         -133315.868223         -855223.925380           -9350.481582   \n",
       "529477         -128750.407703         -841842.148056           -9094.307239   \n",
       "529478         -128879.080536         -873765.673193           -9182.189422   \n",
       "529479         -128678.971810         -872603.283762           -9206.582296   \n",
       "529480         -129305.317753         -876646.910220           -8970.163319   \n",
       "\n",
       "        Principal component 7  label  \n",
       "0                10210.389224      0  \n",
       "1                10014.928220      0  \n",
       "2                10014.928220      0  \n",
       "3                10014.928220      0  \n",
       "4                10188.446052      0  \n",
       "...                       ...    ...  \n",
       "529476           16850.957232      0  \n",
       "529477           10005.865241      0  \n",
       "529478           10266.382651      0  \n",
       "529479           10228.529420      0  \n",
       "529480           10285.549386      0  \n",
       "\n",
       "[529481 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming columns and creating a copy\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "df_cleaned = df.copy()\n",
    "df_cleaned = clean_dataset(df_cleaned)\n",
    "\n",
    "# Resetting index and removing unneeded index column\n",
    "df_cleaned = df_cleaned.reset_index()\n",
    "df_cleaned.drop('index', axis=1, inplace=True)\n",
    "\n",
    "# Saving the label attribute before dropping it\n",
    "df_labels = df_cleaned['label']\n",
    "df_no_labels = df_cleaned.drop('label', axis=1, inplace=False)\n",
    "df_features = df_no_labels.columns.tolist()\n",
    "\n",
    "# Scaling the data\n",
    "df_scaled = StandardScaler().fit_transform(df_no_labels)\n",
    "df_scaled = pd.DataFrame(data=df_scaled, columns=df_features)\n",
    "\n",
    "# Performing PCA\n",
    "pca = PCA(n_components=dimensions_num_for_PCA)\n",
    "principal_components = pca.fit(df_no_labels).transform(df_no_labels)\n",
    "\n",
    "# Creating a DataFrame with principal components\n",
    "principal_component_headings = get_PCA_feature_names(dimensions_num_for_PCA)\n",
    "df_pc = pd.DataFrame(data=principal_components, columns=principal_component_headings)\n",
    "\n",
    "# Concatenating principal components and labels\n",
    "df_final = pd.concat([df_pc, df_labels], axis=1)\n",
    "\n",
    "# Applying LabelBinarizer to the labels\n",
    "lb = LabelBinarizer()\n",
    "df_final['label'] = lb.fit_transform(df_final['label'])\n",
    "\n",
    "# Displaying the final DataFrame\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "529476    0\n",
       "529477    0\n",
       "529478    0\n",
       "529479    0\n",
       "529480    0\n",
       "Name: label, Length: 529481, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_final.drop(['label'], axis = 1)\n",
    "y = df_final['label']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=num_of_splits_for_skf, shuffle=False)\n",
    "skf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object dtype dtype('O') has no native HDF5 equivalent",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Assuming preprocessed_data is a NumPy array containing the preprocessed data\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mwith\u001b[39;00m h5py\u001b[39m.\u001b[39mFile(\u001b[39m'\u001b[39m\u001b[39mpreprocessed_data.h5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> 5\u001b[0m     f\u001b[39m.\u001b[39;49mcreate_dataset(\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m, data\u001b[39m=\u001b[39;49mskf)\n",
      "File \u001b[0;32m~/miniconda3/envs/spectre/lib/python3.9/site-packages/h5py/_hl/group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    180\u001b[0m         parent_path, name \u001b[39m=\u001b[39m name\u001b[39m.\u001b[39mrsplit(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    181\u001b[0m         group \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 183\u001b[0m dsid \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmake_new_dset(group, shape, dtype, data, name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    184\u001b[0m dset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mDataset(dsid)\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/miniconda3/envs/spectre/lib/python3.9/site-packages/h5py/_hl/dataset.py:88\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m         dtype \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m---> 88\u001b[0m     tid \u001b[39m=\u001b[39m h5t\u001b[39m.\u001b[39;49mpy_create(dtype, logical\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     90\u001b[0m \u001b[39m# Legacy\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m((compression, shuffle, fletcher32, maxshape, scaleoffset)) \u001b[39mand\u001b[39;00m chunks \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32mh5py/h5t.pyx:1664\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1688\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5t.pyx:1748\u001b[0m, in \u001b[0;36mh5py.h5t.py_create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object dtype dtype('O') has no native HDF5 equivalent"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Assuming preprocessed_data is a NumPy array containing the preprocessed data\n",
    "with h5py.File('preprocessed_data.h5', 'w') as f:\n",
    "    f.create_dataset('data', data=skf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TF Saved_model\n",
    "spectre_model = tf.saved_model.load(\"/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS/SavedModel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load H5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 03:34:13.057092: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-05-09 03:34:13.057126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: aryn-eos\n",
      "2023-05-09 03:34:13.057134: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: aryn-eos\n",
      "2023-05-09 03:34:13.057293: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 530.41.3\n",
      "2023-05-09 03:34:13.057315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 530.41.3\n",
      "2023-05-09 03:34:13.057321: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 530.41.3\n"
     ]
    }
   ],
   "source": [
    "# H5 Model\n",
    "spectre_model_h5 = keras.models.load_model('/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS/spectre_ddos_h5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H5 Model 2\n",
    "spectre_model_2_h5 = keras.models.load_model('../spectre-ann/Model/DDOS_2/spectre_ddos_2_h5.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tflite Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tflite Model\n",
    "# Load the TFLite model in TFLite Interpreter\n",
    "#interpreter = tf.lite.Interpreter('/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS/spectre_ddos_lite.tflite')\n",
    "#interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "#input_details = interpreter.get_input_details()\n",
    "#output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "    # Load the H5 model\n",
    "#    with h5py.File('/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS/FYP_Finalh5.h5', 'r') as spectre_model:\n",
    "        # Print metadata\n",
    "#        print(\"H5 file metadata:\")\n",
    "#        print(\"==================\")\n",
    "#        for key, value in spectre_model.attrs.items():\n",
    "#            print(f\"{key}: {value}\")\n",
    "#        print(\"==================\")\n",
    "#        print(\"Done!\")\n",
    "#except:\n",
    "#    print(\"Error loading H5 file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the model to predict anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = spectre_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = spectre_model_2_h5.predict(training_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Assuming preprocessed_data is a NumPy array containing the preprocessed data\n",
    "with h5py.File('preprocessed_data.h5', 'w') as f:\n",
    "    f.create_dataset('data', data=preprocessed_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['Detection rate', 'Anomalies detected']\n",
    "y = [detection_rate, anomalies_detected]\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spectre",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1dfc71e7fbfeb8e9159a06fd6d881a402781ddd8e7c98f8d64701fc8c4ad09f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
