{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECTRE-CPU-V2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP PRE-REQUISITES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 03:58:44.725717: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-03 03:58:44.752133: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-03 03:58:44.752697: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-03 03:58:45.416065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "#import keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.models import Model\n",
    "from keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "def escape():\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Linux-6.2.13-zen-1-zen-x86_64-with-glibc2.37\n",
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.9.16 (main, Mar  8 2023, 14:00:05) \n",
      "[GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup INFO level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change: Dataset format used is CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test CSV Dataset Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers match\n"
     ]
    }
   ],
   "source": [
    "# Test Header of the CSV if there is error, run the CICFlowMeter again\n",
    "\n",
    "def read_header(file_path):\n",
    "    return pd.read_csv(file_path, nrows=0).columns\n",
    "\n",
    "directory = \"/home/aryn/spectre-dev/dataset/ISCX-IDS-2012/PCAP-CSV/\"\n",
    "\n",
    "# Get all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "# Read headers from all CSV files\n",
    "headers = [read_header(os.path.join(directory, f)) for f in csv_files]\n",
    "\n",
    "# Check if all headers match\n",
    "if all(h.equals(headers[0]) for h in headers[1:]):\n",
    "    print(\"Headers match\")\n",
    "else:\n",
    "    print(\"Headers do not match\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset with `tf.data.experimental.make_csv_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of CSV files\n",
    "csv_files = glob.glob(\"/home/aryn/spectre-dev/dataset/ISCX-IDS-2012/PCAP-CSV/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Total Fwd Packet', 'Total Bwd packets', 'Total Length of Fwd Packet', 'Total Length of Bwd Packet', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Packet Length Min', 'Packet Length Max', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWR Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Fwd Segment Size Avg', 'Bwd Segment Size Avg', 'Fwd Bytes/Bulk Avg', 'Fwd Packet/Bulk Avg', 'Fwd Bulk Rate Avg', 'Bwd Bytes/Bulk Avg', 'Bwd Packet/Bulk Avg', 'Bwd Bulk Rate Avg', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'FWD Init Win Bytes', 'Bwd Init Win Bytes', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label']\n",
      "84\n"
     ]
    }
   ],
   "source": [
    "# Read the header from one of the CSV files to get column names\n",
    "with open(csv_files[0], \"r\") as f:\n",
    "    header_line = f.readline().strip()\n",
    "    column_names = header_line.split(',')\n",
    "    \n",
    "print(column_names)\n",
    "\n",
    "print(len(column_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the dataset length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records in the dataset: 3612546\n"
     ]
    }
   ],
   "source": [
    "file_pattern = \"/home/aryn/spectre-dev/dataset/ISCX-IDS-2012/PCAP-CSV/*.csv\"\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "dataset_size = 0\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    with open(csv_file, \"r\") as f:\n",
    "        # Subtract 1 to account for the header row\n",
    "        num_records = sum(1 for _ in f) - 1\n",
    "        dataset_size += num_records\n",
    "\n",
    "print(\"Total records in the dataset:\", dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aryn/miniconda3/envs/spectre/lib/python3.9/site-packages/tensorflow/python/data/experimental/ops/readers.py:573: ignore_errors (from tensorflow.python.data.experimental.ops.error_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.ignore_errors` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 03:59:38.934513: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-05-03 03:59:38.934551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: aryn-eos\n",
      "2023-05-03 03:59:38.934558: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: aryn-eos\n",
      "2023-05-03 03:59:38.934780: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 530.41.3\n",
      "2023-05-03 03:59:38.934808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 530.41.3\n",
      "2023-05-03 03:59:38.934817: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 530.41.3\n"
     ]
    }
   ],
   "source": [
    "data_array = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern=csv_files,  # Use the list of CSV file paths\n",
    "    batch_size=2,\n",
    "    label_name=\"Flow ID\",\n",
    "    header=True,\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True,\n",
    "    field_delim=',',\n",
    "    shuffle=True,\n",
    "    column_names=column_names  # Use the column_names list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 03:59:43.409588: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_8' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_8}}]]\n",
      "2023-05-03 03:59:43.410959: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_52' with dtype float and shape [1]\n",
      "\t [[{{node Placeholder/_52}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow ID: b'8.6.0.1-8.0.6.4-0-0-0'\n",
      "Features:\n",
      "  'Src IP'            : b'8.6.0.1'\n",
      "  'Src Port'          : 0\n",
      "  'Dst IP'            : b'8.0.6.4'\n",
      "  'Dst Port'          : 0\n",
      "  'Protocol'          : 0\n",
      "  'Timestamp'         : b'13/06/2010 07:40:55 PM'\n",
      "  'Flow Duration'     : 40004026\n",
      "  'Total Fwd Packet'  : 2\n",
      "  'Total Bwd packets' : 0\n",
      "  'Total Length of Fwd Packet': 0.0\n",
      "  'Total Length of Bwd Packet': 0.0\n",
      "  'Fwd Packet Length Max': 0.0\n",
      "  'Fwd Packet Length Min': 0.0\n",
      "  'Fwd Packet Length Mean': 0.0\n",
      "  'Fwd Packet Length Std': 0.0\n",
      "  'Bwd Packet Length Max': 0.0\n",
      "  'Bwd Packet Length Min': 0.0\n",
      "  'Bwd Packet Length Mean': 0.0\n",
      "  'Bwd Packet Length Std': 0.0\n",
      "  'Flow Bytes/s'      : 0.0\n",
      "  'Flow Packets/s'    : 0.04999496787786484\n",
      "  'Flow IAT Mean'     : 40004024.0\n",
      "  'Flow IAT Std'      : 0.0\n",
      "  'Flow IAT Max'      : 40004024.0\n",
      "  'Flow IAT Min'      : 40004024.0\n",
      "  'Fwd IAT Total'     : 40004024.0\n",
      "  'Fwd IAT Mean'      : 40004024.0\n",
      "  'Fwd IAT Std'       : 0.0\n",
      "  'Fwd IAT Max'       : 40004024.0\n",
      "  'Fwd IAT Min'       : 40004024.0\n",
      "  'Bwd IAT Total'     : 0.0\n",
      "  'Bwd IAT Mean'      : 0.0\n",
      "  'Bwd IAT Std'       : 0.0\n",
      "  'Bwd IAT Max'       : 0.0\n",
      "  'Bwd IAT Min'       : 0.0\n",
      "  'Fwd PSH Flags'     : 0\n",
      "  'Bwd PSH Flags'     : 0\n",
      "  'Fwd URG Flags'     : 0\n",
      "  'Bwd URG Flags'     : 0\n",
      "  'Fwd Header Length' : 0\n",
      "  'Bwd Header Length' : 0\n",
      "  'Fwd Packets/s'     : 0.04999496787786484\n",
      "  'Bwd Packets/s'     : 0.0\n",
      "  'Packet Length Min' : 0.0\n",
      "  'Packet Length Max' : 0.0\n",
      "  'Packet Length Mean': 0.0\n",
      "  'Packet Length Std' : 0.0\n",
      "  'Packet Length Variance': 0.0\n",
      "  'FIN Flag Count'    : 0\n",
      "  'SYN Flag Count'    : 0\n",
      "  'RST Flag Count'    : 0\n",
      "  'PSH Flag Count'    : 0\n",
      "  'ACK Flag Count'    : 0\n",
      "  'URG Flag Count'    : 0\n",
      "  'CWR Flag Count'    : 0\n",
      "  'ECE Flag Count'    : 0\n",
      "  'Down/Up Ratio'     : 0.0\n",
      "  'Average Packet Size': 0.0\n",
      "  'Fwd Segment Size Avg': 0.0\n",
      "  'Bwd Segment Size Avg': 0.0\n",
      "  'Fwd Bytes/Bulk Avg': 0\n",
      "  'Fwd Packet/Bulk Avg': 0\n",
      "  'Fwd Bulk Rate Avg' : 0\n",
      "  'Bwd Bytes/Bulk Avg': 0\n",
      "  'Bwd Packet/Bulk Avg': 0\n",
      "  'Bwd Bulk Rate Avg' : 0\n",
      "  'Subflow Fwd Packets': 2\n",
      "  'Subflow Fwd Bytes' : 0\n",
      "  'Subflow Bwd Packets': 0\n",
      "  'Subflow Bwd Bytes' : 0\n",
      "  'FWD Init Win Bytes': 0\n",
      "  'Bwd Init Win Bytes': 0\n",
      "  'Fwd Act Data Pkts' : 0\n",
      "  'Fwd Seg Size Min'  : 0\n",
      "  'Active Mean'       : 0.0\n",
      "  'Active Std'        : 0.0\n",
      "  'Active Max'        : 0.0\n",
      "  'Active Min'        : 0.0\n",
      "  'Idle Mean'         : 40004024.0\n",
      "  'Idle Std'          : 0.0\n",
      "  'Idle Max'          : 40004024.0\n",
      "  'Idle Min'          : 40004024.0\n",
      "  'Label'             : b'NeedManualLabel'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dataset Output\n",
    "\n",
    "# Unbatch the dataset\n",
    "unbatched_data = data_array.unbatch()\n",
    "\n",
    "# Take the first 2 elements\n",
    "dataset_xray = unbatched_data.take(1)\n",
    "\n",
    "# Print the first 2 elements with proper formatting\n",
    "for features, label in dataset_xray:\n",
    "    print(\"Flow ID: {}\".format(label.numpy()))\n",
    "    print(\"Features:\")\n",
    "    for key, value in features.items():\n",
    "        print(\"  {!r:20s}: {}\".format(key, value.numpy()))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = dataset_size\n",
    "train_size = int(0.8 * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "train_data = data_array.take(train_size)\n",
    "test_data = data_array.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 04:00:00.557183: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_44' with dtype int32 and shape [1]\n",
      "\t [[{{node Placeholder/_44}}]]\n",
      "2023-05-03 04:00:00.558398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_25' with dtype float and shape [1]\n",
      "\t [[{{node Placeholder/_25}}]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first element to get the input shape\n",
    "for features, labels in train_data.take(1):\n",
    "    input_shape = list(features.values())[0].shape\n",
    "\n",
    "num_classes = 84\n",
    "\n",
    "# Create the ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                192       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 84)                2772      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,044\n",
      "Trainable params: 5,044\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(features, labels):\n",
    "    features_values = [tf.cast(value, tf.float32) for key, value in features.items() if key != 'Label']\n",
    "    return tf.stack(features_values, axis=-1), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.map(preprocess_data)\n",
    "test_data = test_data.map(preprocess_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batched = train_data.batch(32)\n",
    "test_data_batched = test_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch the dataset\n",
    "#train_data_batched = data_array.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 04:01:40.085745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_56' with dtype int32 and shape [1]\n",
      "\t [[{{node Placeholder/_56}}]]\n",
      "2023-05-03 04:01:40.086974: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_37' with dtype float and shape [1]\n",
      "\t [[{{node Placeholder/_37}}]]\n",
      "2023-05-03 04:01:40.150762: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "{{function_node __wrapped__MakeIterator_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to float is not supported\n\t [[{{node Cast}}]] [Op:MakeIterator]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_data_batched, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/spectre/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/spectre/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: {{function_node __wrapped__MakeIterator_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cast string to float is not supported\n\t [[{{node Cast}}]] [Op:MakeIterator]"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_data_batched, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_data.batch(32))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export as SavedModel\n",
    "tf.saved_model.save(my_model, '/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS/SavedModel/')\n",
    "\n",
    "# Export as Keras Model\n",
    "my_model.save(\"/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS/spectre_ddos_hd5\")\n",
    "\n",
    "# Export as Keras H5 Model\n",
    "my_model.save(\"/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS/spectre_ddos_h5.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN ACTIVATION GRAPH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
