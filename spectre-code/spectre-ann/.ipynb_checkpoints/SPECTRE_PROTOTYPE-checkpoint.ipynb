{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECTRE PROTOTYPE\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-23 12:21:44.235210: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kafka'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m LabelBinarizer\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkafka\u001b[39;00m \u001b[39mimport\u001b[39;00m KafkaConsumer, KafkaProducer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kafka'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from kafka import KafkaConsumer, KafkaProducer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.saved_model.load(\"/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS_2/SavedModel\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prod_data_preprocess(df):\n",
    "    def clean_dataset(df):\n",
    "        assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "        df.dropna(inplace=True)\n",
    "        indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "        return df[indices_to_keep]\n",
    "\n",
    "    def get_PCA_feature_names(num_of_pca_components):\n",
    "        feature_names = []\n",
    "        for i in range(num_of_pca_components):    \n",
    "            feature_names.append(f\"Principal component {i+1}\")\n",
    "        return feature_names\n",
    "\n",
    "    # Clean the dataset.\n",
    "    df = clean_dataset(df)\n",
    "\n",
    "    # Reset the index and remove the unneeded index column.\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    # Check if the 'label' column exists in the DataFrame.\n",
    "    if 'label' in df.columns:\n",
    "        # Save the label attribute before dropping it.\n",
    "        df_labels = df['label']\n",
    "        df_no_labels = df.drop('label', axis=1)\n",
    "    else:\n",
    "        # If the 'label' column does not exist, use the DataFrame as is.\n",
    "        df_no_labels = df\n",
    "        df_labels = None\n",
    "\n",
    "    # Scale the data.\n",
    "    df_scaled = StandardScaler().fit_transform(df_no_labels)\n",
    "\n",
    "    # Perform PCA.\n",
    "    pca = PCA(n_components=7)\n",
    "    principal_components = pca.fit_transform(df_no_labels)\n",
    "\n",
    "    # Create a DataFrame with principal components.\n",
    "    principal_component_headings = get_PCA_feature_names(7)\n",
    "    df_pc = pd.DataFrame(data=principal_components, columns=principal_component_headings)\n",
    "\n",
    "    if df_labels is not None:\n",
    "        # Concatenate principal components and labels.\n",
    "        df_final = pd.concat([df_pc, df_labels], axis=1)\n",
    "\n",
    "        # Apply LabelBinarizer to the labels.\n",
    "        lb = LabelBinarizer()\n",
    "        df_final['label'] = lb.fit_transform(df_final['label'])\n",
    "    else:\n",
    "        df_final = df_pc\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
