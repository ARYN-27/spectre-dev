{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPECTRE-CPU-V2\n",
    "> Trained with **CICIDS2017**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP PRE-REQUISITES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T09:29:48.852790Z",
     "iopub.status.busy": "2023-05-24T09:29:48.852539Z",
     "iopub.status.idle": "2023-05-24T09:29:50.842644Z",
     "shell.execute_reply": "2023-05-24T09:29:50.841848Z",
     "shell.execute_reply.started": "2023-05-24T09:29:48.852769Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import layers\n",
    "\n",
    "#import keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from keras.models import Model\n",
    "from keras import layers, models\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#from tabulate import tabulate\n",
    "\n",
    "import seaborn as sns # Graphing, built ontop of MatPlot for ease-of-use and nicer diagrams.\n",
    "import sklearn # For Machine Learning algorithms\n",
    "import scikitplot # Confusion matrix plotting\n",
    "from sklearn.decomposition import PCA # For PCA dimensionality reduction technique\n",
    "from sklearn.preprocessing import StandardScaler # For scaling to unit scale, before PCA application\n",
    "from sklearn.preprocessing import LabelBinarizer # For converting categorical data into numeric, for modeling stage\n",
    "from sklearn.model_selection import StratifiedKFold # For optimal train_test splitting, for model input data\n",
    "from sklearn.model_selection import train_test_split # For basic dataset splitting\n",
    "from sklearn.neighbors import KNeighborsClassifier # K-Nearest Neighbors ML classifier (default n. of neighbors = 5)\n",
    "from scikitplot.metrics import plot_confusion_matrix # For plotting confusion matrices\n",
    "from sklearn.metrics import accuracy_score # For getting the accuracy of a model's predictions\n",
    "from sklearn.metrics import classification_report # Various metrics for model performance\n",
    "from sklearn.neural_network import MLPClassifier # For Neural Network classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def escape():\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T09:29:50.844411Z",
     "iopub.status.busy": "2023-05-24T09:29:50.843958Z",
     "iopub.status.idle": "2023-05-24T09:29:50.848038Z",
     "shell.execute_reply": "2023-05-24T09:29:50.847354Z",
     "shell.execute_reply.started": "2023-05-24T09:29:50.844395Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Linux-5.15.90.1-microsoft-standard-WSL2-x86_64-with-glibc2.29\n",
      "Tensor Flow Version: 2.12.0\n",
      "Keras Version: 2.12.0\n",
      "\n",
      "Python 3.8.10 (default, Mar 13 2023, 10:26:41) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tf.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENVIRONMENT SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup INFO level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T09:29:50.849023Z",
     "iopub.status.busy": "2023-05-24T09:29:50.848823Z",
     "iopub.status.idle": "2023-05-24T09:29:50.853324Z",
     "shell.execute_reply": "2023-05-24T09:29:50.852434Z",
     "shell.execute_reply.started": "2023-05-24T09:29:50.849007Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('INFO')\n",
    "\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Useful environment variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T09:29:50.855068Z",
     "iopub.status.busy": "2023-05-24T09:29:50.854407Z",
     "iopub.status.idle": "2023-05-24T09:29:50.858448Z",
     "shell.execute_reply": "2023-05-24T09:29:50.857513Z",
     "shell.execute_reply.started": "2023-05-24T09:29:50.855045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Max number of permutations to run. Can be altered for needs.\n",
    "number_of_permutations = 100\n",
    "\n",
    "# 10 folds is usually the heuristic to follow for larger datasets of around this size.\n",
    "num_of_splits_for_skf = 10\n",
    "\n",
    "# Seed value to pass into models so that repeated runs result in the same output\n",
    "seed_val = 1\n",
    "\n",
    "# Number of statistical distance measures to run (for the results, columns section)\n",
    "num_of_statistical_dist_measures = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Reduced dimensions' variable for altering the number of PCA principal components. Can be altered for needs.\n",
    "# Only 7 principal components needed when using non-normalised PCA dataset.\n",
    "dimensions_num_for_PCA = 7\n",
    "\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)  # Replace np.inf and -np.inf with np.nan\n",
    "    df.dropna(inplace=True)  # Drop rows containing np.nan\n",
    "    return df\n",
    "\n",
    "def get_PCA_feature_names(num_of_pca_components):\n",
    "    feature_names = []\n",
    "    for i in range(num_of_pca_components):    \n",
    "        feature_names.append(f\"Principal component {i+1}\")\n",
    "    return feature_names\n",
    "\n",
    "# Renaming columns and creating a copy\n",
    "df = DDoS_Kaggle.copy()\n",
    "df = df.rename(columns=lambda x: x.strip().lower().replace(' ', '_').replace('(', '').replace(')', ''))\n",
    "df_cleaned = clean_dataset(df).compute()\n",
    "\n",
    "# Resetting index and removing unneeded index column\n",
    "df_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Saving the label attribute before dropping it\n",
    "df_labels = df_cleaned['label']\n",
    "df_no_labels = df_cleaned.drop('label', axis=1)\n",
    "df_features = df_no_labels.columns.tolist()\n",
    "\n",
    "# Scaling the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_no_labels)\n",
    "df_scaled = pd.DataFrame(data=df_scaled, columns=df_features)\n",
    "\n",
    "# Performing PCA\n",
    "dimensions_num_for_PCA = 2  # You need to define dimensions_num_for_PCA\n",
    "pca = PCA(n_components=dimensions_num_for_PCA)\n",
    "principal_components = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Creating a DataFrame with principal components\n",
    "principal_component_headings = get_PCA_feature_names(dimensions_num_for_PCA)\n",
    "df_pc = pd.DataFrame(data=principal_components, columns=principal_component_headings)\n",
    "\n",
    "# Concatenating principal components and labels\n",
    "df_final = pd.concat([df_pc, df_labels], axis=1)\n",
    "\n",
    "# Applying LabelBinarizer to the labels\n",
    "lb = LabelBinarizer()\n",
    "df_final['label'] = lb.fit_transform(df_final['label'])\n",
    "\n",
    "# Displaying the final DataFrame\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Fold Cross Validation and Stratified splitting**\n",
    "\n",
    "K-Fold is a technique which splits data into K folds (splits). Train of a model K times, and for each training iteration, K-Fold selects a different fold to use for testing; the remaining K - 1 folds become the training data. Typically, the optimal K value can be derived using the size of your dataset (num of rows). Ideally, each fold should be statistically representative of the population. Too small and it won't be useful. Too large, and you lose the positives from doing K-Fold.\n",
    "\n",
    "You can use Stratified splitting with K-Fold, which ensures balance between some criteria (balances out the classes) e.g. equal portion of label classes in each fold.\n",
    "\n",
    "Class Imbalance is a significant issue in the ML/ Data Mining domain. It leads to incorrect results e.g. if one fold had all of 1 label (accidentally), then it would produce terrible predictive results as it wouldn't know what the other label class data point would look like. You can only work with the data you have, so this has to be dealt with.\n",
    "\n",
    "Benefits of K-Fold:\n",
    "- Use more of the data towards making a succesful model.\n",
    "- Obtain K models to evaluate, can improve the confidence that you have selected an appropriate model algorithm and cleaned/ prepared the data correctly, e.g. normal split with 1 model, one doesn't know if it's good or not- it could be heavily biased. Multiple models ensures less bias and increased variance.\n",
    "- Looking at the accuracy results from each of the k-Folds, you can identify data issues e.g. a certain fold performs really badly. Could this suggest that more cleaning is required? Maybe the data preparation was performed incorrectly?\n",
    "- If all folds return similar accuracies, one can be more confident that a deployed model will perform similarly to how one expects.\n",
    "\n",
    "Issues with K-Fold:\n",
    "- Creating K separate models requires more computation.\n",
    "- If you haven't got much data, you might not get many folds. Less folds means K-Fold loses its benefits.\n",
    "- If K is very large, each fold is small, and harder to ensure statistical distribution of.\n",
    "- Choosing the best of K models introduces bias. Real world data could perform better under a more general, lower performing model.\n",
    "\n",
    "Code reference: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.350345Z",
     "iopub.status.idle": "2023-05-24T09:29:53.350532Z",
     "shell.execute_reply": "2023-05-24T09:29:53.350453Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.350444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "225706    0\n",
       "225707    0\n",
       "225708    0\n",
       "225709    0\n",
       "225710    0\n",
       "Name: label, Length: 225711, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separating the label so that the answers aren't provided to the model, in training.\n",
    "X = df_final.drop(['label'], axis = 1)\n",
    "y = df_final['label']\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.351244Z",
     "iopub.status.idle": "2023-05-24T09:29:53.351429Z",
     "shell.execute_reply": "2023-05-24T09:29:53.351350Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.351342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Principal component 1</th>\n",
       "      <th>Principal component 2</th>\n",
       "      <th>Principal component 3</th>\n",
       "      <th>Principal component 4</th>\n",
       "      <th>Principal component 5</th>\n",
       "      <th>Principal component 6</th>\n",
       "      <th>Principal component 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.632317e+07</td>\n",
       "      <td>-177588.423798</td>\n",
       "      <td>-158328.262332</td>\n",
       "      <td>3.274166e+06</td>\n",
       "      <td>-644672.422205</td>\n",
       "      <td>-65463.389477</td>\n",
       "      <td>-2.488349e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.630598e+07</td>\n",
       "      <td>-175956.557639</td>\n",
       "      <td>-146308.360104</td>\n",
       "      <td>-6.182039e+05</td>\n",
       "      <td>-660559.724997</td>\n",
       "      <td>-66403.655703</td>\n",
       "      <td>-2.500578e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.630655e+07</td>\n",
       "      <td>-176002.193903</td>\n",
       "      <td>-146668.436861</td>\n",
       "      <td>-4.974704e+05</td>\n",
       "      <td>-660076.496646</td>\n",
       "      <td>-66383.896019</td>\n",
       "      <td>-2.500178e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-3.630711e+07</td>\n",
       "      <td>-176054.438478</td>\n",
       "      <td>-147043.488746</td>\n",
       "      <td>-3.752421e+05</td>\n",
       "      <td>-659575.485264</td>\n",
       "      <td>-66353.363288</td>\n",
       "      <td>-2.499773e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.632317e+07</td>\n",
       "      <td>-177588.424395</td>\n",
       "      <td>-158328.262578</td>\n",
       "      <td>3.274166e+06</td>\n",
       "      <td>-644672.421279</td>\n",
       "      <td>-65463.388671</td>\n",
       "      <td>-2.488349e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225706</th>\n",
       "      <td>-3.630640e+07</td>\n",
       "      <td>-175986.939817</td>\n",
       "      <td>-146564.360752</td>\n",
       "      <td>-5.315339e+05</td>\n",
       "      <td>-660217.323093</td>\n",
       "      <td>-66393.258881</td>\n",
       "      <td>-2.500293e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225707</th>\n",
       "      <td>-3.630626e+07</td>\n",
       "      <td>-175975.278900</td>\n",
       "      <td>-146473.928435</td>\n",
       "      <td>-5.616025e+05</td>\n",
       "      <td>-660338.262449</td>\n",
       "      <td>-66398.743473</td>\n",
       "      <td>-2.500392e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225708</th>\n",
       "      <td>-3.630622e+07</td>\n",
       "      <td>-175972.744882</td>\n",
       "      <td>-146454.001685</td>\n",
       "      <td>-5.682723e+05</td>\n",
       "      <td>-660364.983726</td>\n",
       "      <td>-66399.860056</td>\n",
       "      <td>-2.500414e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225709</th>\n",
       "      <td>-3.630660e+07</td>\n",
       "      <td>-176009.636226</td>\n",
       "      <td>-146737.014042</td>\n",
       "      <td>-4.781892e+05</td>\n",
       "      <td>-659998.750229</td>\n",
       "      <td>-66339.920855</td>\n",
       "      <td>-2.500141e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225710</th>\n",
       "      <td>-3.630630e+07</td>\n",
       "      <td>-175977.931623</td>\n",
       "      <td>-146503.718510</td>\n",
       "      <td>-5.517941e+05</td>\n",
       "      <td>-660296.900808</td>\n",
       "      <td>-66396.918961</td>\n",
       "      <td>-2.500357e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225711 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Principal component 1  Principal component 2  Principal component 3   \n",
       "0               -3.632317e+07         -177588.423798         -158328.262332  \\\n",
       "1               -3.630598e+07         -175956.557639         -146308.360104   \n",
       "2               -3.630655e+07         -176002.193903         -146668.436861   \n",
       "3               -3.630711e+07         -176054.438478         -147043.488746   \n",
       "4               -3.632317e+07         -177588.424395         -158328.262578   \n",
       "...                       ...                    ...                    ...   \n",
       "225706          -3.630640e+07         -175986.939817         -146564.360752   \n",
       "225707          -3.630626e+07         -175975.278900         -146473.928435   \n",
       "225708          -3.630622e+07         -175972.744882         -146454.001685   \n",
       "225709          -3.630660e+07         -176009.636226         -146737.014042   \n",
       "225710          -3.630630e+07         -175977.931623         -146503.718510   \n",
       "\n",
       "        Principal component 4  Principal component 5  Principal component 6   \n",
       "0                3.274166e+06         -644672.422205          -65463.389477  \\\n",
       "1               -6.182039e+05         -660559.724997          -66403.655703   \n",
       "2               -4.974704e+05         -660076.496646          -66383.896019   \n",
       "3               -3.752421e+05         -659575.485264          -66353.363288   \n",
       "4                3.274166e+06         -644672.421279          -65463.388671   \n",
       "...                       ...                    ...                    ...   \n",
       "225706          -5.315339e+05         -660217.323093          -66393.258881   \n",
       "225707          -5.616025e+05         -660338.262449          -66398.743473   \n",
       "225708          -5.682723e+05         -660364.983726          -66399.860056   \n",
       "225709          -4.781892e+05         -659998.750229          -66339.920855   \n",
       "225710          -5.517941e+05         -660296.900808          -66396.918961   \n",
       "\n",
       "        Principal component 7  \n",
       "0               -2.488349e+06  \n",
       "1               -2.500578e+06  \n",
       "2               -2.500178e+06  \n",
       "3               -2.499773e+06  \n",
       "4               -2.488349e+06  \n",
       "...                       ...  \n",
       "225706          -2.500293e+06  \n",
       "225707          -2.500392e+06  \n",
       "225708          -2.500414e+06  \n",
       "225709          -2.500141e+06  \n",
       "225710          -2.500357e+06  \n",
       "\n",
       "[225711 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.352335Z",
     "iopub.status.idle": "2023-05-24T09:29:53.352524Z",
     "shell.execute_reply": "2023-05-24T09:29:53.352443Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.352434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=10, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=num_of_splits_for_skf, shuffle=False)\n",
    "skf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, splitting the data into train and test data, using the optimal splitting techniques of K-Fold and Stratified Splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.353385Z",
     "iopub.status.idle": "2023-05-24T09:29:53.353564Z",
     "shell.execute_reply": "2023-05-24T09:29:53.353488Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.353479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train length:  203140\n",
      "y_train length:  203140\n",
      "X_test length:  22571\n",
      "y_test length:  22571\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    reshaped_y_train = np.asarray(y_train).reshape(-1, 1)\n",
    "    reshaped_y_test = np.asarray(y_test).reshape(-1, 1)\n",
    "    \n",
    "print( 'X_train length: ', len(X_train) ) # To check if splits worked\n",
    "print( 'y_train length: ', len(y_train) )\n",
    "print( 'X_test length: ', len(X_test) )\n",
    "print( 'y_test length: ', len(y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.354754Z",
     "iopub.status.idle": "2023-05-24T09:29:53.355001Z",
     "shell.execute_reply": "2023-05-24T09:29:53.354899Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.354888Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.355763Z",
     "iopub.status.idle": "2023-05-24T09:29:53.355948Z",
     "shell.execute_reply": "2023-05-24T09:29:53.355870Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.355861Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 09:37:01.985835: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:02.008707: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:02.008913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:02.010070: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:02.010256: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:02.010416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:03.247980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:03.248280: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:03.248300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-24 09:37:03.248540: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-24 09:37:03.248582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from keras.regularizers import l1, l2, l1_l2\n",
    "\n",
    "# Define the ANN model\n",
    "\n",
    "#model = Sequential([\n",
    "#    Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.5),\n",
    "#    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.5),\n",
    "#    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.5),\n",
    "#    Dense(1, activation='sigmoid')\n",
    "#])\n",
    "\n",
    "\n",
    "#model = Sequential([\n",
    "#    Dense(256, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.5),\n",
    "#    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.5),\n",
    "#    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.5),\n",
    "#    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.5),\n",
    "#    Dense(1, activation='sigmoid')\n",
    "#])\n",
    "\n",
    "#model = Sequential([\n",
    "#    Dense(512, kernel_initializer='he_normal', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.001)),\n",
    "#    LeakyReLU(alpha=0.1),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.4),\n",
    "#    Dense(256, kernel_initializer='he_normal', kernel_regularizer=l2(0.001)),\n",
    "#    LeakyReLU(alpha=0.1),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.4),\n",
    "#    Dense(128, kernel_initializer='he_normal', kernel_regularizer=l2(0.001)),\n",
    "#    LeakyReLU(alpha=0.1),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.4),\n",
    "#    Dense(64, kernel_initializer='he_normal', kernel_regularizer=l2(0.001)),\n",
    "#    LeakyReLU(alpha=0.1),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.4),\n",
    "#    Dense(32, kernel_initializer='he_normal', kernel_regularizer=l2(0.001)),\n",
    "#    LeakyReLU(alpha=0.1),\n",
    "#    BatchNormalization(),\n",
    "#    Dropout(0.4),\n",
    "#    Dense(1, activation='sigmoid')\n",
    "#])\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, kernel_initializer='he_normal', input_shape=(X_train.shape[1],), kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, kernel_initializer='he_normal', kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, kernel_initializer='he_normal', kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, kernel_initializer='he_normal', kernel_regularizer=l1_l2(l1=0.0001, l2=0.0001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.356650Z",
     "iopub.status.idle": "2023-05-24T09:29:53.356833Z",
     "shell.execute_reply": "2023-05-24T09:29:53.356754Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.356746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               2048      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32)               128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,233\n",
      "Trainable params: 46,273\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.357529Z",
     "iopub.status.idle": "2023-05-24T09:29:53.357706Z",
     "shell.execute_reply": "2023-05-24T09:29:53.357630Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.357622Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(loss=keras.losses.binary_crossentropy, optimizer=keras.optimizers.RMSprop(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.358547Z",
     "iopub.status.idle": "2023-05-24T09:29:53.358724Z",
     "shell.execute_reply": "2023-05-24T09:29:53.358647Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.358639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 09:37:07.690526: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-24 09:37:08.274363: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f05371d3260 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-24 09:37:08.274408: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-05-24 09:37:08.304692: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-24 09:37:08.571354: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-05-24 09:37:08.778398: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9029/9029 [==============================] - 159s 17ms/step - loss: 0.4183 - accuracy: 0.9233 - val_loss: 0.2864 - val_accuracy: 0.9582\n",
      "Epoch 2/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2787 - accuracy: 0.9386 - val_loss: 0.3104 - val_accuracy: 0.9244\n",
      "Epoch 3/50\n",
      "9029/9029 [==============================] - 154s 17ms/step - loss: 0.2581 - accuracy: 0.9400 - val_loss: 0.4620 - val_accuracy: 0.8119\n",
      "Epoch 4/50\n",
      "9029/9029 [==============================] - 154s 17ms/step - loss: 0.2426 - accuracy: 0.9428 - val_loss: 0.2528 - val_accuracy: 0.9518\n",
      "Epoch 5/50\n",
      "9029/9029 [==============================] - 159s 18ms/step - loss: 0.2388 - accuracy: 0.9433 - val_loss: 0.1752 - val_accuracy: 0.9710\n",
      "Epoch 6/50\n",
      "9029/9029 [==============================] - 163s 18ms/step - loss: 0.2363 - accuracy: 0.9432 - val_loss: 0.2235 - val_accuracy: 0.9687\n",
      "Epoch 7/50\n",
      "9029/9029 [==============================] - 155s 17ms/step - loss: 0.2335 - accuracy: 0.9422 - val_loss: 0.2303 - val_accuracy: 0.9675\n",
      "Epoch 8/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2318 - accuracy: 0.9438 - val_loss: 0.2660 - val_accuracy: 0.9490\n",
      "Epoch 9/50\n",
      "9029/9029 [==============================] - 149s 17ms/step - loss: 0.2305 - accuracy: 0.9429 - val_loss: 0.1794 - val_accuracy: 0.9579\n",
      "Epoch 10/50\n",
      "9029/9029 [==============================] - 151s 17ms/step - loss: 0.2277 - accuracy: 0.9433 - val_loss: 0.1873 - val_accuracy: 0.9605\n",
      "Epoch 11/50\n",
      "9029/9029 [==============================] - 154s 17ms/step - loss: 0.2276 - accuracy: 0.9438 - val_loss: 0.6334 - val_accuracy: 0.5790\n",
      "Epoch 12/50\n",
      "9029/9029 [==============================] - 158s 17ms/step - loss: 0.2248 - accuracy: 0.9446 - val_loss: 0.1612 - val_accuracy: 0.9657\n",
      "Epoch 13/50\n",
      "9029/9029 [==============================] - 168s 19ms/step - loss: 0.2268 - accuracy: 0.9428 - val_loss: 0.1760 - val_accuracy: 0.9623\n",
      "Epoch 14/50\n",
      "9029/9029 [==============================] - 155s 17ms/step - loss: 0.2220 - accuracy: 0.9447 - val_loss: 0.1588 - val_accuracy: 0.9699\n",
      "Epoch 15/50\n",
      "9029/9029 [==============================] - 161s 18ms/step - loss: 0.2228 - accuracy: 0.9446 - val_loss: 0.1915 - val_accuracy: 0.9629\n",
      "Epoch 16/50\n",
      "9029/9029 [==============================] - 161s 18ms/step - loss: 0.2247 - accuracy: 0.9440 - val_loss: 0.2279 - val_accuracy: 0.9630\n",
      "Epoch 17/50\n",
      "9029/9029 [==============================] - 160s 18ms/step - loss: 0.2232 - accuracy: 0.9432 - val_loss: 0.2642 - val_accuracy: 0.9498\n",
      "Epoch 18/50\n",
      "9029/9029 [==============================] - 160s 18ms/step - loss: 0.2252 - accuracy: 0.9437 - val_loss: 0.1842 - val_accuracy: 0.9612\n",
      "Epoch 19/50\n",
      "9029/9029 [==============================] - 154s 17ms/step - loss: 0.2243 - accuracy: 0.9429 - val_loss: 0.2173 - val_accuracy: 0.9673\n",
      "Epoch 20/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2237 - accuracy: 0.9430 - val_loss: 0.1889 - val_accuracy: 0.9636\n",
      "Epoch 21/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2208 - accuracy: 0.9441 - val_loss: 0.1644 - val_accuracy: 0.9659\n",
      "Epoch 22/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2223 - accuracy: 0.9438 - val_loss: 0.1620 - val_accuracy: 0.9625\n",
      "Epoch 23/50\n",
      "9029/9029 [==============================] - 156s 17ms/step - loss: 0.2214 - accuracy: 0.9440 - val_loss: 0.1619 - val_accuracy: 0.9644\n",
      "Epoch 24/50\n",
      "9029/9029 [==============================] - 158s 18ms/step - loss: 0.2237 - accuracy: 0.9433 - val_loss: 0.3452 - val_accuracy: 0.8272\n",
      "Epoch 25/50\n",
      "9029/9029 [==============================] - 158s 17ms/step - loss: 0.2235 - accuracy: 0.9429 - val_loss: 0.3308 - val_accuracy: 0.8613\n",
      "Epoch 26/50\n",
      "9029/9029 [==============================] - 154s 17ms/step - loss: 0.2237 - accuracy: 0.9429 - val_loss: 0.2403 - val_accuracy: 0.9305\n",
      "Epoch 27/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2248 - accuracy: 0.9425 - val_loss: 0.4146 - val_accuracy: 0.8124\n",
      "Epoch 28/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2208 - accuracy: 0.9439 - val_loss: 0.2068 - val_accuracy: 0.9604\n",
      "Epoch 29/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2210 - accuracy: 0.9440 - val_loss: 0.1673 - val_accuracy: 0.9627\n",
      "Epoch 30/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2210 - accuracy: 0.9431 - val_loss: 0.1587 - val_accuracy: 0.9684\n",
      "Epoch 31/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2203 - accuracy: 0.9432 - val_loss: 0.2040 - val_accuracy: 0.9721\n",
      "Epoch 32/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2217 - accuracy: 0.9436 - val_loss: 0.1608 - val_accuracy: 0.9584\n",
      "Epoch 33/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2199 - accuracy: 0.9440 - val_loss: 0.1571 - val_accuracy: 0.9624\n",
      "Epoch 34/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2208 - accuracy: 0.9427 - val_loss: 0.1584 - val_accuracy: 0.9610\n",
      "Epoch 35/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2221 - accuracy: 0.9438 - val_loss: 0.1605 - val_accuracy: 0.9603\n",
      "Epoch 36/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2232 - accuracy: 0.9425 - val_loss: 0.2032 - val_accuracy: 0.9593\n",
      "Epoch 37/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2194 - accuracy: 0.9438 - val_loss: 0.2390 - val_accuracy: 0.9631\n",
      "Epoch 38/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2221 - accuracy: 0.9432 - val_loss: 0.2974 - val_accuracy: 0.8748\n",
      "Epoch 39/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2176 - accuracy: 0.9445 - val_loss: 0.1727 - val_accuracy: 0.9578\n",
      "Epoch 40/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2199 - accuracy: 0.9442 - val_loss: 0.1818 - val_accuracy: 0.9634\n",
      "Epoch 41/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2199 - accuracy: 0.9432 - val_loss: 0.1747 - val_accuracy: 0.9574\n",
      "Epoch 42/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2214 - accuracy: 0.9436 - val_loss: 0.2448 - val_accuracy: 0.9503\n",
      "Epoch 43/50\n",
      "9029/9029 [==============================] - 156s 17ms/step - loss: 0.2186 - accuracy: 0.9439 - val_loss: 0.2020 - val_accuracy: 0.9561\n",
      "Epoch 44/50\n",
      "9029/9029 [==============================] - 156s 17ms/step - loss: 0.2209 - accuracy: 0.9437 - val_loss: 0.1748 - val_accuracy: 0.9635\n",
      "Epoch 45/50\n",
      "9029/9029 [==============================] - 154s 17ms/step - loss: 0.2188 - accuracy: 0.9446 - val_loss: 0.1595 - val_accuracy: 0.9597\n",
      "Epoch 46/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2186 - accuracy: 0.9445 - val_loss: 0.1750 - val_accuracy: 0.9537\n",
      "Epoch 47/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2190 - accuracy: 0.9442 - val_loss: 0.1754 - val_accuracy: 0.9609\n",
      "Epoch 48/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2200 - accuracy: 0.9438 - val_loss: 0.2012 - val_accuracy: 0.9666\n",
      "Epoch 49/50\n",
      "9029/9029 [==============================] - 152s 17ms/step - loss: 0.2193 - accuracy: 0.9442 - val_loss: 0.2236 - val_accuracy: 0.9671\n",
      "Epoch 50/50\n",
      "9029/9029 [==============================] - 153s 17ms/step - loss: 0.2208 - accuracy: 0.9433 - val_loss: 0.1882 - val_accuracy: 0.9594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0669065940>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "#model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2)\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.359487Z",
     "iopub.status.idle": "2023-05-24T09:29:53.359672Z",
     "shell.execute_reply": "2023-05-24T09:29:53.359593Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.359584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 9s 6ms/step - loss: 0.1870 - accuracy: 0.9601\n",
      "Test set accuracy: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test set accuracy: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.360405Z",
     "iopub.status.idle": "2023-05-24T09:29:53.360585Z",
     "shell.execute_reply": "2023-05-24T09:29:53.360507Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.360499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1411/1411 [==============================] - 4s 3ms/step\n",
      "Confusion Matrix:\n",
      " [[18409  1010]\n",
      " [  789 24935]]\n",
      "Precision: 0.96\n",
      "Recall: 0.97\n",
      "F1-score: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# Make predictionsHDF5\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Calculate performance metrics\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1-score: {:.2f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPORT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-24T09:29:53.361637Z",
     "iopub.status.idle": "2023-05-24T09:29:53.361823Z",
     "shell.execute_reply": "2023-05-24T09:29:53.361744Z",
     "shell.execute_reply.started": "2023-05-24T09:29:53.361735Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 11:46:15.332324: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:15.348098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:15.363765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:15.381637: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:15.966332: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:16.033312: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:16.103931: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:16.173833: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS_2/A/SavedModel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 11:46:17.193123: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:17.209650: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:17.224186: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:17.239120: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:17.601875: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:17.670104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:17.737370: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-05-24 11:46:17.807350: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]\n",
      "\t [[{{node inputs}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS_2/A/spectre_ddos_2_A_hd5/assets\n"
     ]
    }
   ],
   "source": [
    "# Export as SavedModel\n",
    "tf.saved_model.save(model, '/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS_2/A/SavedModel/')\n",
    "\n",
    "# Export as Keras Model\n",
    "model.save(\"/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS_2/A/spectre_ddos_2_A_hd5\")\n",
    "\n",
    "# Export as Keras H5 Model\n",
    "model.save(\"/home/aryn/spectre-dev/spectre-code/spectre-ann/Model/DDOS_2/A/spectre_ddos_2_A_h5.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
